{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISIT = 'FIRST'\n",
    "env = gym.make(\"FrozenLake-v0\")\n",
    "num_episodes = 1000000\n",
    "epsilon = .15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average reward: 0.0\n",
      "Average reward: 0.0\n",
      "Average reward: 0.0\n",
      "Average reward: 0.0\n",
      "Average reward: 0.0\n",
      "Average reward: 0.0\n",
      "Average reward: 0.0\n",
      "Average reward: 0.0030000000000000027\n",
      "Average reward: 0.005555555555555554\n",
      "Average reward: 0.009600000000000003\n",
      "Average reward: 0.012363636363636361\n",
      "Average reward: 0.015166666666666658\n",
      "Average reward: 0.01799999999999998\n",
      "Average reward: 0.021428571428571408\n",
      "Average reward: 0.021466666666666672\n",
      "Average reward: 0.023374999999999976\n",
      "Average reward: 0.02482352941176468\n",
      "Average reward: 0.02555555555555553\n",
      "Average reward: 0.026421052631578915\n",
      "Average reward: 0.027199999999999964\n",
      "Average reward: 0.027142857142857118\n",
      "Average reward: 0.02781818181818179\n",
      "Average reward: 0.028608695652173874\n",
      "Average reward: 0.02874999999999999\n",
      "Average reward: 0.029599999999999998\n",
      "Average reward: 0.030769230769230767\n",
      "Average reward: 0.03207407407407401\n",
      "Average reward: 0.032499999999999925\n",
      "Average reward: 0.03365517241379303\n",
      "Average reward: 0.03593333333333325\n",
      "Average reward: 0.037548387096774105\n",
      "Average reward: 0.03906249999999997\n",
      "Average reward: 0.040666666666666546\n",
      "Average reward: 0.04135294117647043\n",
      "Average reward: 0.042914285714285585\n",
      "Average reward: 0.04399999999999989\n",
      "Average reward: 0.045297297297297257\n",
      "Average reward: 0.046105263157894726\n",
      "Average reward: 0.047230769230769194\n",
      "Average reward: 0.04769999999999999\n",
      "Average reward: 0.048390243902439053\n",
      "Average reward: 0.049047619047619145\n",
      "Average reward: 0.0500465116279071\n",
      "Average reward: 0.05077272727272741\n",
      "Average reward: 0.051555555555555674\n",
      "Average reward: 0.051913043478261006\n",
      "Average reward: 0.05234042553191505\n",
      "Average reward: 0.05325000000000029\n",
      "Average reward: 0.05395918367346961\n",
      "Average reward: 0.0544000000000002\n",
      "Average reward: 0.055137254901960975\n",
      "Average reward: 0.05550000000000024\n",
      "Average reward: 0.05584905660377381\n",
      "Average reward: 0.05670370370370387\n",
      "Average reward: 0.05690909090909114\n",
      "Average reward: 0.0576071428571431\n",
      "Average reward: 0.05810526315789499\n",
      "Average reward: 0.05855172413793131\n",
      "Average reward: 0.05884745762711895\n",
      "Average reward: 0.05936666666666694\n",
      "Average reward: 0.05967213114754123\n",
      "Average reward: 0.06019354838709708\n",
      "Average reward: 0.06079365079365113\n",
      "Average reward: 0.06131250000000034\n",
      "Average reward: 0.06203076923076962\n",
      "Average reward: 0.06215151515151544\n",
      "Average reward: 0.06244776119403014\n",
      "Average reward: 0.06279411764705914\n",
      "Average reward: 0.06330434782608721\n",
      "Average reward: 0.06377142857142887\n",
      "Average reward: 0.06380281690140857\n",
      "Average reward: 0.06430555555555574\n",
      "Average reward: 0.06473972602739748\n",
      "Average reward: 0.06497297297297312\n",
      "Average reward: 0.0653333333333335\n",
      "Average reward: 0.0655263157894739\n",
      "Average reward: 0.06553246753246766\n",
      "Average reward: 0.06561538461538473\n",
      "Average reward: 0.06569620253164563\n",
      "Average reward: 0.06617500000000015\n",
      "Average reward: 0.06641975308641987\n",
      "Average reward: 0.06663414634146343\n",
      "Average reward: 0.06679518072289149\n",
      "Average reward: 0.06723809523809518\n",
      "Average reward: 0.06750588235294112\n",
      "Average reward: 0.06779069767441857\n",
      "Average reward: 0.06786206896551719\n",
      "Average reward: 0.06811363636363633\n",
      "Average reward: 0.06840449438202242\n",
      "Average reward: 0.06880000000000003\n",
      "Average reward: 0.06892307692307692\n",
      "Average reward: 0.0690000000000001\n",
      "Average reward: 0.06911827956989255\n",
      "Average reward: 0.0693617021276597\n",
      "Average reward: 0.06943157894736857\n",
      "Average reward: 0.06966666666666672\n",
      "Average reward: 0.06960824742268051\n",
      "Average reward: 0.06973469387755125\n",
      "Average reward: 0.06983838383838406\n",
      "Average reward: 0.07020000000000012\n",
      "Average reward: 0.07061386138613865\n",
      "Average reward: 0.07090196078431366\n",
      "Average reward: 0.07139805825242722\n",
      "Average reward: 0.07196153846153859\n",
      "Average reward: 0.07228571428571436\n",
      "Average reward: 0.07254716981132091\n",
      "Average reward: 0.07287850467289755\n",
      "Average reward: 0.07305555555555589\n",
      "Average reward: 0.07328440366972516\n",
      "Average reward: 0.07350909090909136\n",
      "Average reward: 0.07392792792792842\n",
      "Average reward: 0.07414285714285755\n"
     ]
    }
   ],
   "source": [
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "k_s_a = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "result_sum = 0\n",
    "avg_reward = 0\n",
    "\n",
    "for i in range(1,num_episodes):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    G = 0.0\n",
    "    seq = []\n",
    "    while not done:\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else: \n",
    "            action = np.argmax(Q[state,:])\n",
    "        next_state,reward,done,_ = env.step(action)\n",
    "        seq.append((state,action))\n",
    "        G += reward\n",
    "        state = next_state\n",
    "    alpha = 1.0 / i\n",
    "    avg_reward += alpha * (G - avg_reward)\n",
    "    \n",
    "    if VISIT is 'EVERY':\n",
    "        for (state,action) in seq:\n",
    "            k_s_a[state,action] += 1.0\n",
    "            alpha = 1.0/ k_s_a[state,action]\n",
    "            Q[state,action] += alpha * (G - Q[state,action])\n",
    "    else:\n",
    "        visited_state_actions = set()\n",
    "        for (state,action) in seq:\n",
    "            if (state,action) not in visited_state_actions:\n",
    "                k_s_a[state,action] += 1.0\n",
    "                alpha = 1.0/ k_s_a[state,action]\n",
    "                Q[state,action] += alpha * (G - Q[state,action])\n",
    "\n",
    "    if i % 500 == 0 and i is not 0:\n",
    "        print(\"Average reward: \" + str(avg_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ml env",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
